{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GjFBXCxgR_H"
      },
      "outputs": [],
      "source": [
        "# 선생님 코드\n",
        "\n",
        "# train : 2000장\n",
        "# val : 1000장\n",
        "# test : 22장"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 경로 지정\n",
        "train_dir = '/content/drive/MyDrive/Colab Notebooks/사물지능_딥러닝_2022/data/dogs_vs_cats_small/train'\n",
        "val_dir = '/content/drive/MyDrive/Colab Notebooks/사물지능_딥러닝_2022/data/dogs_vs_cats_small/validation'\n",
        "test_dir ='/content/drive/MyDrive/Colab Notebooks/사물지능_딥러닝_2022/data/dogs_vs_cats_small/test'"
      ],
      "metadata": {
        "id": "j3htOVmQvKHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(len(os.listdir(train_dir)))\n",
        "print(len(os.listdir(val_dir)))\n",
        "print(len(os.listdir(test_dir)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCKer1k4vrnR",
        "outputId": "b92ed42a-4a28-4d7f-b0eb-6d942b1a5006"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "2\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 하나의 변수에 이미지파일 전부다 합치기\n",
        "# 픽셀값 0~255 > 0~1\n",
        "# 이미지 크기 동일하게 만들어주기 (150,150)\n",
        "# 라벨링\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# 픽셀값 변환\n",
        "train_gen = ImageDataGenerator(rescale = 1./255)\n",
        "test_gen = ImageDataGenerator(rescale = 1./255)\n",
        "val_gen = ImageDataGenerator(rescale = 1./255)"
      ],
      "metadata": {
        "id": "m32H43JmwjZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# flow_from_directory()\n",
        "train_generator = train_gen.flow_from_directory(\n",
        "    train_dir, # train 이미지 경로    \n",
        "    target_size = (150,150), # 변환할 이미지의 크기\n",
        "    batch_size = 100, # 한번에 변환할 이미지 갯수\n",
        "    class_mode = 'binary' # 라벨링 진행, categorical : 다중분류\n",
        "    # 폴더별로 라벨링을 진행 cats(0) , dogs(1)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILVoqA-PwnHR",
        "outputId": "aa156096-0eb7-495e-ae7a-f540525719ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_generator = val_gen.flow_from_directory(\n",
        "    val_dir, # train 이미지 경로    \n",
        "    target_size = (150,150), # 변환할 이미지의 크기\n",
        "    batch_size = 100, # 한번에 변환할 이미지 갯수\n",
        "    class_mode = 'binary' # 라벨링 진행, categorical : 다중분류\n",
        "    # 폴더별로 라벨링을 진행 cats(0) , dogs(1)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8MaFtQownFB",
        "outputId": "bc0368f7-0799-4236-8a26-a1ee6f2955d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator = test_gen.flow_from_directory(\n",
        "    test_dir, # train 이미지 경로    \n",
        "    target_size = (150,150), # 변환할 이미지의 크기\n",
        "    batch_size = 100, # 한번에 변환할 이미지 갯수\n",
        "    class_mode = 'binary' # 라벨링 진행, categorical : 다중분류\n",
        "    # 폴더별로 라벨링을 진행 cats(0) , dogs(1)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7hXntR9wnCo",
        "outputId": "44313b6f-6dd0-4912-e2dd-db35f56dede9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 22 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 라벨링 결과 확인\n",
        "print(train_generator.class_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5i8zFEFwnAa",
        "outputId": "89e1801a-6595-4e03-86ed-3dba9118b834"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'cats': 0, 'dogs': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN 모델 설계\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten"
      ],
      "metadata": {
        "id": "1XNfAN6Xwm9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 딥러닝 모델 생성\n",
        "model1 = Sequential()\n",
        "\n",
        "# 입력층, 특징추출부\n",
        "model1.add(Conv2D(\n",
        "    filters = 32, # 특징의 갯수\n",
        "    kernel_size = (3,3), # 특징의 크기\n",
        "    input_shape = (150,150,3), # 입력 데이터의 모양\n",
        "    padding = 'same', # 입력이미지와 출력이미지의 크기를 동일하게\n",
        "    activation = 'relu'\n",
        "))\n",
        "\n",
        "model1.add(MaxPool2D(\n",
        "    pool_size = (2,2)\n",
        "))\n",
        "\n",
        "model1.add(Conv2D(\n",
        "    filters = 64, # 특징의 갯수\n",
        "    kernel_size = (3,3), # 특징의 크기\n",
        "    input_shape = (150,150,3), # 입력 데이터의 모양\n",
        "    padding = 'same', # 입력이미지와 출력이미지의 크기를 동일하게\n",
        "    activation = 'relu'\n",
        "))\n",
        "\n",
        "model1.add(MaxPool2D(\n",
        "    pool_size = (2,2)\n",
        "))\n",
        "################특징 추출부 끝###############\n",
        "model1.add(Flatten())\n",
        "################분류부 시작#################\n",
        "# 위에서 특징을 추출했기때문에 층을 깊게 쌓지 않아도됨\n",
        "model1.add(Dense(units = 256, activation = 'relu'))\n",
        "\n",
        "# 출력층\n",
        "model1.add(Dense(units = 1, activation = 'sigmoid'))"
      ],
      "metadata": {
        "id": "PYhFnhwEwm7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile(\n",
        "    loss = 'binary_crossentropy',\n",
        "    optimizer = 'adam',\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "GXhAJRhYwm5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.fit_generator(\n",
        "    generator = train_generator,\n",
        "    epochs = 20,\n",
        "    validation_data = val_generator\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHrf0RJ_wm2x",
        "outputId": "e0bfff84-d999-4fb6-b06e-aa7d80cfbbe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "20/20 [==============================] - 1030s 52s/step - loss: 1.6378 - accuracy: 0.4965 - val_loss: 0.6953 - val_accuracy: 0.4810\n",
            "Epoch 2/20\n",
            "20/20 [==============================] - 12s 602ms/step - loss: 0.6883 - accuracy: 0.5405 - val_loss: 0.6904 - val_accuracy: 0.5310\n",
            "Epoch 3/20\n",
            "20/20 [==============================] - 12s 591ms/step - loss: 0.6499 - accuracy: 0.6355 - val_loss: 0.6361 - val_accuracy: 0.6110\n",
            "Epoch 4/20\n",
            "20/20 [==============================] - 12s 599ms/step - loss: 0.6152 - accuracy: 0.6650 - val_loss: 0.6215 - val_accuracy: 0.6580\n",
            "Epoch 5/20\n",
            "20/20 [==============================] - 12s 598ms/step - loss: 0.5068 - accuracy: 0.7700 - val_loss: 0.5998 - val_accuracy: 0.6750\n",
            "Epoch 6/20\n",
            "20/20 [==============================] - 13s 652ms/step - loss: 0.4210 - accuracy: 0.8095 - val_loss: 0.5879 - val_accuracy: 0.6930\n",
            "Epoch 7/20\n",
            "20/20 [==============================] - 12s 601ms/step - loss: 0.3216 - accuracy: 0.8770 - val_loss: 0.6788 - val_accuracy: 0.6950\n",
            "Epoch 8/20\n",
            "20/20 [==============================] - 12s 598ms/step - loss: 0.2353 - accuracy: 0.9170 - val_loss: 0.7798 - val_accuracy: 0.6810\n",
            "Epoch 9/20\n",
            "20/20 [==============================] - 12s 597ms/step - loss: 0.1663 - accuracy: 0.9460 - val_loss: 0.7689 - val_accuracy: 0.7090\n",
            "Epoch 10/20\n",
            "20/20 [==============================] - 12s 599ms/step - loss: 0.1067 - accuracy: 0.9695 - val_loss: 0.8290 - val_accuracy: 0.7110\n",
            "Epoch 11/20\n",
            "20/20 [==============================] - 12s 596ms/step - loss: 0.0807 - accuracy: 0.9820 - val_loss: 0.8582 - val_accuracy: 0.7140\n",
            "Epoch 12/20\n",
            "20/20 [==============================] - 12s 599ms/step - loss: 0.0400 - accuracy: 0.9930 - val_loss: 0.9828 - val_accuracy: 0.7190\n",
            "Epoch 13/20\n",
            "20/20 [==============================] - 12s 593ms/step - loss: 0.0315 - accuracy: 0.9940 - val_loss: 1.0351 - val_accuracy: 0.6980\n",
            "Epoch 14/20\n",
            "20/20 [==============================] - 12s 597ms/step - loss: 0.0251 - accuracy: 0.9985 - val_loss: 1.0713 - val_accuracy: 0.7030\n",
            "Epoch 15/20\n",
            "20/20 [==============================] - 12s 597ms/step - loss: 0.0127 - accuracy: 0.9995 - val_loss: 1.2243 - val_accuracy: 0.7050\n",
            "Epoch 16/20\n",
            "20/20 [==============================] - 12s 605ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.2478 - val_accuracy: 0.7080\n",
            "Epoch 17/20\n",
            "20/20 [==============================] - 12s 611ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.3271 - val_accuracy: 0.7160\n",
            "Epoch 18/20\n",
            "20/20 [==============================] - 12s 604ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.3562 - val_accuracy: 0.7080\n",
            "Epoch 19/20\n",
            "20/20 [==============================] - 12s 597ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.4132 - val_accuracy: 0.7120\n",
            "Epoch 20/20\n",
            "20/20 [==============================] - 12s 595ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.4287 - val_accuracy: 0.7080\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcce519e6d0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 과대적합이 관찰되었음\n",
        "# 학습데이터 증가 2000 > 3000\n",
        "# 딥러닝 모델 재설계 > dropout()\n",
        "# 학습데이터 augmentation(확장) : 기존의 이미지에 변화를 줘서 이미지를 사용"
      ],
      "metadata": {
        "id": "cKo4XF0zwm0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 확장(증식)\n",
        "train_aug = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    rotation_range = 20,\n",
        "    width_shift_range = 0.1,\n",
        "    height_shift_range = 0.1,\n",
        "    shear_range = 0.1,\n",
        "    zoom_range = 0.1,\n",
        "    horizontal_flip = True,\n",
        "    fill_mode = 'nearest' # 비어있는 부분을 가장 가까이에 있는 값으로 채움\n",
        ")\n",
        "\n",
        "train_aug_generator = train_aug.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size = (150,150),\n",
        "    batch_size = 100,\n",
        "    class_mode = 'binary'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2rZDMi5wmyL",
        "outputId": "5f74bf2d-c4b3-48bf-c909-653356ea089c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN 모델 설계\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
        "\n",
        "# 딥러닝 모델 생성\n",
        "model1 = Sequential()\n",
        "\n",
        "# 입력층, 특징추출부\n",
        "model1.add(Conv2D(\n",
        "    filters = 32, # 특징의 갯수\n",
        "    kernel_size = (3,3), # 특징의 크기\n",
        "    input_shape = (150,150,3), # 입력 데이터의 모양\n",
        "    padding = 'same', # 입력이미지와 출력이미지의 크기를 동일하게\n",
        "    activation = 'relu'\n",
        "))\n",
        "\n",
        "model1.add(MaxPool2D(\n",
        "    pool_size = (2,2)\n",
        "))\n",
        "\n",
        "model1.add(Conv2D(\n",
        "    filters = 64, # 특징의 갯수\n",
        "    kernel_size = (3,3), # 특징의 크기\n",
        "    input_shape = (150,150,3), # 입력 데이터의 모양\n",
        "    padding = 'same', # 입력이미지와 출력이미지의 크기를 동일하게\n",
        "    activation = 'relu'\n",
        "))\n",
        "\n",
        "model1.add(MaxPool2D(\n",
        "    pool_size = (2,2)\n",
        "))\n",
        "\n",
        "################특징 추출부 끝###############\n",
        "model1.add(Flatten())\n",
        "################분류부 시작#################\n",
        "# 위에서 특징을 추출했기때문에 층을 깊게 쌓지 않아도됨\n",
        "model1.add(Dense(units = 256, activation = 'relu'))\n",
        "\n",
        "model1.add(Dropout(0.4))\n",
        "\n",
        "# 출력층\n",
        "model1.add(Dense(units = 1, activation = 'sigmoid'))"
      ],
      "metadata": {
        "id": "OydUFeFtwmvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile(\n",
        "    loss = 'binary_crossentropy',\n",
        "    optimizer = 'adam',\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "Q_FUBMzVwmtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.fit_generator(\n",
        "    generator = train_aug_generator,\n",
        "    epochs = 20,\n",
        "    validation_data = val_generator\n",
        ")"
      ],
      "metadata": {
        "id": "042ynp8Jwmqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전이학습\n",
        "# 누군가가 만들어놓은 모델 가져오기\n",
        "# 특성추출방식\n",
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "conv_base = VGG16(\n",
        "    weights = 'imagenet', # imagenet에서 사용한 가중치 가져오기\n",
        "    include_top = False, # 분류기를 사용할것인가? \n",
        "    input_shape = (150,150,3)\n",
        ")"
      ],
      "metadata": {
        "id": "QeWNuN0Kwmoa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2e02466-9727-4a24-df6a-1e2546a317db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary()"
      ],
      "metadata": {
        "id": "blHG2O22wmlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 동결\n",
        "# 가중치가 갱신되는것을 막는것\n",
        "\n",
        "# 학습 가능한 가중치의 갯수 확인\n",
        "len(conv_base.trainable_weights)"
      ],
      "metadata": {
        "id": "hZbDRC2Twmjg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5429534-16ac-4149-da61-156de81546c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG16 전체 층에대해 동결\n",
        "conv_base.trainable = False"
      ],
      "metadata": {
        "id": "JTBgxuAtwmhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 가능한 가중치의 갯수 확인\n",
        "len(conv_base.trainable_weights)"
      ],
      "metadata": {
        "id": "L8A59kfgwme4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "649aaa2c-0070-4ae9-f73e-3e5df52647f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 동결된 conv를 사용해서 모델 설계\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "model2 = Sequential()\n",
        "\n",
        "model2.add(conv_base) # 전이학습할 모델의 특성추출부 사용하기\n",
        "\n",
        "model2.add(Flatten())\n",
        "\n",
        "model2.add(Dense(units = 256, activation = 'relu'))\n",
        "\n",
        "\n",
        "# 출력층\n",
        "model2.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "\n",
        "\n",
        "model2.summary()"
      ],
      "metadata": {
        "id": "-7JZCx1Wwmcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(loss = 'binary_crossentropy',\n",
        "               optimizer = 'adam',\n",
        "               metrics = ['accuracy']\n",
        "               )"
      ],
      "metadata": {
        "id": "8q3uwsKCwmaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.fit_generator(\n",
        "    generator = train_aug_generator,\n",
        "    epochs = 20,\n",
        "    validation_data = val_generator\n",
        ")"
      ],
      "metadata": {
        "id": "BYoezR9cwmX4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6fe960d-2577-43c6-9436-4f80bde53804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "20/20 [==============================] - 781s 39s/step - loss: 0.9818 - accuracy: 0.6070 - val_loss: 0.4286 - val_accuracy: 0.8240\n",
            "Epoch 2/20\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.3910 - accuracy: 0.8315 - val_loss: 0.3040 - val_accuracy: 0.8950\n",
            "Epoch 3/20\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.3239 - accuracy: 0.8645 - val_loss: 0.2670 - val_accuracy: 0.8940\n",
            "Epoch 4/20\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.2850 - accuracy: 0.8810 - val_loss: 0.2485 - val_accuracy: 0.9010\n",
            "Epoch 5/20\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.2543 - accuracy: 0.8975 - val_loss: 0.2442 - val_accuracy: 0.9040\n",
            "Epoch 6/20\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.2498 - accuracy: 0.9015 - val_loss: 0.2387 - val_accuracy: 0.9050\n",
            "Epoch 7/20\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.2281 - accuracy: 0.9100 - val_loss: 0.2293 - val_accuracy: 0.9080\n",
            "Epoch 8/20\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.2231 - accuracy: 0.9080 - val_loss: 0.2261 - val_accuracy: 0.9150\n",
            "Epoch 9/20\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.2157 - accuracy: 0.9130 - val_loss: 0.2397 - val_accuracy: 0.9030\n",
            "Epoch 10/20\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.1906 - accuracy: 0.9220 - val_loss: 0.2265 - val_accuracy: 0.9110\n",
            "Epoch 11/20\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.1832 - accuracy: 0.9240 - val_loss: 0.2291 - val_accuracy: 0.9110\n",
            "Epoch 12/20\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.2018 - accuracy: 0.9175 - val_loss: 0.2487 - val_accuracy: 0.8990\n",
            "Epoch 13/20\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.1949 - accuracy: 0.9255 - val_loss: 0.2942 - val_accuracy: 0.8800\n",
            "Epoch 14/20\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.1894 - accuracy: 0.9230 - val_loss: 0.2795 - val_accuracy: 0.8910\n",
            "Epoch 15/20\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.1679 - accuracy: 0.9305 - val_loss: 0.2436 - val_accuracy: 0.9100\n",
            "Epoch 16/20\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.1769 - accuracy: 0.9300 - val_loss: 0.2416 - val_accuracy: 0.9070\n",
            "Epoch 17/20\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.1530 - accuracy: 0.9400 - val_loss: 0.2764 - val_accuracy: 0.8940\n",
            "Epoch 18/20\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.1524 - accuracy: 0.9440 - val_loss: 0.2495 - val_accuracy: 0.9050\n",
            "Epoch 19/20\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.1448 - accuracy: 0.9440 - val_loss: 0.2527 - val_accuracy: 0.9010\n",
            "Epoch 20/20\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.1352 - accuracy: 0.9450 - val_loss: 0.2477 - val_accuracy: 0.9060\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4e6597eb10>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 미세조정방식"
      ],
      "metadata": {
        "id": "WdOm50kUwmVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model2에서 학습가능한 가중치의 갯수\n",
        "len(model2.trainable_weights)-"
      ],
      "metadata": {
        "id": "d2bX5JxtwmTA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecc7eb61-034d-45ca-e8a1-d8ee6db3a850"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary()"
      ],
      "metadata": {
        "id": "DUFK832jwmQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base = VGG16(\n",
        "    weights = 'imagenet', # imagenet에서 사용한 가중치 가져오기\n",
        "    include_top = False, # 분류기를 사용할것인가? \n",
        "    input_shape = (150,150,3)\n",
        ")"
      ],
      "metadata": {
        "id": "KhYzEEkte7Jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# block5_conv1 ~ 3 층을 학습시켜보자\n",
        "\n",
        "# block5_conv1 층부터 하위의 층의 동결을 해제\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "  if layer.name == 'block4_conv1':\n",
        "    set_trainable = True\n",
        "  \n",
        "  if set_trainable == True:\n",
        "    layer.trainable = True\n",
        "  else:\n",
        "    layer.trainable = False\n"
      ],
      "metadata": {
        "id": "jJLijl6HwmOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 동결된 conv를 사용해서 모델 설계\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "model2 = Sequential()\n",
        "model2.add(conv_base) # 전이학습할 모델의 특성추출부 사용하기\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(units = 256, activation = 'relu'))\n",
        "# 출력층\n",
        "model2.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "model2.summary()"
      ],
      "metadata": {
        "id": "_1XRXa49cYGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(model2.trainable_weights)"
      ],
      "metadata": {
        "id": "y0uFdx1EwmMQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c332151a-cd4b-4f8f-9add-4d2d59001bbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(loss = 'binary_crossentropy',\n",
        "               optimizer = 'adam',\n",
        "               metrics = ['accuracy']\n",
        "               )"
      ],
      "metadata": {
        "id": "wxbFmJU9fn46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.fit_generator(\n",
        "    generator = train_aug_generator,\n",
        "    epochs = 20,\n",
        "    validation_data = val_generator\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKA5Nlj9fnzv",
        "outputId": "6674224d-6a86-47f5-d932-92e5185508a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "20/20 [==============================] - 23s 1s/step - loss: 1.3311 - accuracy: 0.4870 - val_loss: 0.7094 - val_accuracy: 0.4580\n",
            "Epoch 2/20\n",
            "20/20 [==============================] - 22s 1s/step - loss: 0.6938 - accuracy: 0.5085 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 3/20\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 4/20\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 5/20\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 6/20\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 7/20\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.6932 - accuracy: 0.4750 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 8/20\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 9/20\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 10/20\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.6932 - accuracy: 0.4800 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 11/20\n",
            "20/20 [==============================] - 22s 1s/step - loss: 0.6932 - accuracy: 0.4820 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 12/20\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 13/20\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.6932 - accuracy: 0.4930 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 14/20\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 15/20\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.6932 - accuracy: 0.4930 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 16/20\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 17/20\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 18/20\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.6932 - accuracy: 0.4920 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 19/20\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.6932 - accuracy: 0.4780 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 20/20\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4e54104fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 과적합 방지\n",
        "- dropout : 앞층과 뒷층간의 파라미터수 차이가 큰 곳에 주로 배치 (0.5이하로)\n",
        "- BatchNormalizer : CNN에서 과적합 방지 과거에는 dropout을 이용해 과적합으 방지했다면 최근에는 CNN과 한쌍으로 BatchNormalizer로 과적합 방지 한다. (정규화), BM의 위치는 정해져있다. Conv2D와 Activation층 사이에 넣어준다. (Activation하면 약간의 정규화하는 기능이 있어서 그전에 넣어주는 것이다)"
      ],
      "metadata": {
        "id": "G9m6-fTPm4vL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN\n",
        "\n",
        "- convolution(특성 추출) : 이미지에 필터를 씌우고 같은 위치끼리 곱하고 결과들을 더해서 하나의 픽셀 값으로 저장, \n",
        "- zero padding : 컨볼루션하면 이미지가 축소됨, 이미지 크게 유지하고 싶을 때 씀\n",
        "- pooling(특성 선택, 이미지 축소) : 주로 maxpooling 씀 \n",
        "- Flatten : 다차원 배열을 1차원 배열로 변환해주는 것 (Conv1D, RNN은 어짜피 1차원이라 Flatten 쓸필요 없음)"
      ],
      "metadata": {
        "id": "Ibu0b77ru-s3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 전이학습\n"
      ],
      "metadata": {
        "id": "_G_OXwIgx59Q"
      }
    }
  ]
}